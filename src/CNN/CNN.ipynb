{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccQI8qR7cVCi"
      },
      "source": [
        "#Convolution Neural Network"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw-gOW6z2oyW",
        "outputId": "f3445606-e58a-4ba2-aa60-574f98eb2af8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ-8goLqcVCo"
      },
      "source": [
        "#Part - 1: Building The CNN\n",
        "#Importing the Keras libraries and packages\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9x1DZgycVCp"
      },
      "source": [
        "#Initializing the CNN\n",
        "\n",
        "classifier = Sequential()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rATjvh1gcVCp"
      },
      "source": [
        "#Step - 1: Convolution\n",
        "\n",
        "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qASr2ptmcVCq"
      },
      "source": [
        "#Step - 2: Pooling\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fCn2qB5cVCr"
      },
      "source": [
        "#Step - 3: Flattening\n",
        "\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD6ef5KXcVCs"
      },
      "source": [
        "#Step - 4: Fully Connection\n",
        "\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIcZ1JB0cVCu"
      },
      "source": [
        "#Compiling the CNN\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQtng5Z0cVCu",
        "outputId": "33e9b61a-9903-423a-fd4f-3ca1a7d27f89"
      },
      "source": [
        "#Part - 2: Fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('drive/MyDrive/datasetCNN/training_set',\n",
        "                                                 target_size=(64, 64),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('drive/MyDrive/datasetCNN/test_set',\n",
        "                                                        target_size=(64, 64),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "classifier.fit_generator(training_set,\n",
        "                    steps_per_epoch=100,\n",
        "                    epochs=5,\n",
        "                    validation_data=test_set,\n",
        "                    validation_steps=2000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.5325 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 1666s 17s/step - loss: 0.6874 - accuracy: 0.5325 - val_loss: 0.6642 - val_accuracy: 0.6105\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 566s 6s/step - loss: 0.6567 - accuracy: 0.6116\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 346s 3s/step - loss: 0.6151 - accuracy: 0.6575\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 213s 2s/step - loss: 0.6024 - accuracy: 0.6797\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 131s 1s/step - loss: 0.5865 - accuracy: 0.6825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8a9e577f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2un6eDSIcVCv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}